{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e48089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import tensorflow\n",
    "import sklearn\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d07fc3",
   "metadata": {},
   "source": [
    "### Load the data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f12900",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('clean_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4895436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aca7e0",
   "metadata": {},
   "source": [
    "These functions are used to print the unique values of every feature, and the number of missing values for each feature. The loaded dataset is already preprocessed, so all the values are numbers between 0 and 1 and there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c8580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTER FOR UNIQUE VALUES\n",
    "def get_uniques(dataframe):\n",
    "    for feature in dataframe.columns:\n",
    "\n",
    "        print(f\"Feature {feature}: \\n{list(pd.Series(dataframe[feature]).unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTER FOR MISSING VALUES\n",
    "def get_missing_values(dataframe):\n",
    "    for col in dataframe.isnull():\n",
    "        all = list()\n",
    "        print(f'Feature {col}:\\n\\n')\n",
    "        for index, instance in enumerate(dataframe.isnull()[col]):\n",
    "            if instance is True:\n",
    "                all.append(index)\n",
    "        print(f'Missing instances: {all}')\n",
    "        print('Number of missing instances: ', len(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0aaa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET UNIQUE VALUES\n",
    "print(get_uniques(dataframe))\n",
    "\n",
    "# GET MISSING VALUE\n",
    "print(get_missing_values(dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb53488",
   "metadata": {},
   "source": [
    "### Define functions for calculating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a187c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_fun(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_fun(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_fun(y_true, y_pred):\n",
    "    precision = precision_fun(y_true, y_pred)\n",
    "    recall = recall_fun(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8776cb2",
   "metadata": {},
   "source": [
    "### Define functions to be used for the Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53889018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframes_for_training(dataframe, split_frac=0.8):\n",
    "    \"\"\"\n",
    "    Generates training and testing dataframes from a complete dataframe, according to the split_frac parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    train_data = dataframe.sample(frac=split_frac, random_state=314)\n",
    "    test_data = dataframe.drop(train_data.index)\n",
    "    \n",
    "    X_train = train_data.loc[:, train_data.columns != 'Churn']\n",
    "    X_test = test_data.loc[:, test_data.columns != 'Churn']\n",
    "    y_train = train_data.loc[:, train_data.columns == 'Churn']\n",
    "    y_test = test_data.loc[:, test_data.columns == 'Churn']\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2246904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_individual(counter, population):\n",
    "    \"\"\"\n",
    "    If counter is 0, return the individual with the highest prob\n",
    "    If counter is 1, return the second individual with the highest prob\n",
    "    If counter is 2, return the third individual withthe highest prob\n",
    "    \"\"\"\n",
    "    index = counter + 1\n",
    "    probabilities = [ind[1] for ind in population]\n",
    "    sorted_probs = sorted(probabilities, key=float)\n",
    "    max_prob = probabilities[-index]\n",
    "    max_individual = [ind[0] for ind in population if ind[1] == max_prob][0]\n",
    "    \n",
    "    return max_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc699e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_random_individuals(num_individuals, num_features, max_features=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Randomly generates individuals\n",
    "\n",
    "    The number of individuals to generate is given by the num_individuals parameter\n",
    "    The length of each individual is equal to the num_features parameter\n",
    "    The maximum number of active features for every individual is given by the max_features parameter\n",
    "    \"\"\"\n",
    "    if verbose: print('GENERATING RANDOM INDIVIDUALS.... ')\n",
    "        \n",
    "    individuals = list()\n",
    "    \n",
    "    for _ in range(num_individuals):\n",
    "        individual = ''\n",
    "        for col in range(num_features):\n",
    "            # For each char in the individual, a 1 or a 0 is randomly generated\n",
    "            if individual.count('1') == max_features:\n",
    "                individual += '0'\n",
    "                continue\n",
    "                \n",
    "            individual += str(random.randint(0, 1))\n",
    "            \n",
    "        if verbose: print(f'Genrated a new indivudal: {individual}')\n",
    "        individuals.append(individual)\n",
    "        \n",
    "    if verbose: print(f'Generated list of {num_individuals} individuals: {individuals}')\n",
    "        \n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad075bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(X, verbose=False):\n",
    "    \"\"\"\n",
    "    X: training dataset to be used. Its shape is used to set the input shape for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    if verbose: print('MODEL SUMMARY: \\n')\n",
    "    if verbose: print(model.summary())\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_weights(population):\n",
    "    \"\"\"\n",
    "    Calculate weights from the population filled with the accuracies\n",
    "    \"\"\"\n",
    "    total_accuracies = 0\n",
    "    new_population = []\n",
    "    \n",
    "    # Get the sum of all accuracies of the population\n",
    "    for individual in population:\n",
    "        total_accuracies += individual[1]\n",
    "        \n",
    "    # For each individual, calculate its weight by dividing its accuracy by the overall sum calculated above\n",
    "    for individual in population:\n",
    "        weight = individual[1]/total_accuracies\n",
    "        # Store the individual and its weight in the final population list\n",
    "        new_population.append((individual[0], float(weight*100)))\n",
    "        \n",
    "    return new_population\n",
    "\n",
    "\n",
    "\n",
    "def get_fitness_func(individual, dataframe, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate accuracy for the individual passed as parameter.\n",
    "    Both the dataframe and the y_data parameters are used for training and evaluating the model.\n",
    "    \"\"\"\n",
    "    if verbose: print('Calculating accuracy for individual ', individual)\n",
    "    \n",
    "    # generate_dataframes_for_training() function splits a given dataset into training and test data, \n",
    "    # and separates labels and rest of features\n",
    "    X_train, X_test, y_train, y_test = generate_dataframes_for_training(dataframe)\n",
    "    \n",
    "    X_train = X_train.loc[:, [True if individual[i] == '1' else False for i in range(len(individual))]]\n",
    "    X_test = X_test.loc[:, [True if individual[i] == '1' else False for i in range(len(individual))]]    \n",
    "    \n",
    "    model = create_model(X_train, individual)\n",
    "    \n",
    "    X_train = np.asarray(X_train).astype(np.float64)\n",
    "    X_test = np.asarray(X_test).astype(np.float64)\n",
    "    y_train = np.asarray(y_train).astype(np.float64)\n",
    "    y_test = np.asarray(y_test).astype(np.float64)\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100, verbose=1 if verbose else 0)\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred.round())\n",
    "    if verbose: print(f\"Accuracy for the classifier trained for individual {individual}: \", accuracy)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def fill_population(individuals, dataframe, verbose=False):\n",
    "    \"\"\"\n",
    "    Fills the population list with individuals and their weights\n",
    "    \"\"\"\n",
    "    population = list()\n",
    "    \n",
    "    for individual in individuals:\n",
    "        \n",
    "        # Get the value of the fitness function (accuracy of the model)\n",
    "        if verbose: print(f'Calculating fitness function value for individual {individual}')\n",
    "        accuracy = get_fitness_func(individual, dataframe, verbose)\n",
    "        \n",
    "        # Check that the value is not the goal state (in this case, an accuracy of 80% is a terminal state)\n",
    "        if float(accuracy) > 0.8:\n",
    "            if verbose: print(f'Goal state found for individual {individual}')\n",
    "            return individual\n",
    "            \n",
    "        individual_complete = (individual, accuracy)\n",
    "        population.append(individual_complete)\n",
    "        \n",
    "    # The final population list is created, which contains each individual together with its weight\n",
    "    # (weights will be used in the reproduction step)\n",
    "    new_population = get_weights(population)\n",
    "    if verbose: print(f'Generated population list (with weights): {new_population}')\n",
    "    \n",
    "    return new_population\n",
    "\n",
    "\n",
    "\n",
    "def choose_parents(population, counter):\n",
    "    \"\"\"\n",
    "    From the population, weighting the probabilities of an individual being chosen via the fitness\n",
    "    function, takes randomly two individual to reproduce\n",
    "    Population is a list of tuples, where the first element is the individual and the second\n",
    "    one is the probability associated to it.\n",
    "    To avoid generating repeated individuals, 'counter' parameter is used to pick parents in different ways, thus\n",
    "    generating different individuals\n",
    "    \"\"\"\n",
    "    # Pick random parent Number 1 and Number 2\n",
    "    # (get_n_individual() function randomly picks an individual following the distribution of the weights)\n",
    "    if counter == 0:        \n",
    "        parent_1 = get_n_individual(0, population)        \n",
    "        parent_2 = get_n_individual(1, population)\n",
    "    elif counter == 1:\n",
    "        parent_1 = get_n_individual(0, population)        \n",
    "        parent_2 = get_n_individual(2, population)\n",
    "        \n",
    "    else:\n",
    "        probabilities = (individual[1] for individual in population)\n",
    "        individuals = [individual[0] for individual in population]\n",
    "        parent_1, parent_2 = random.choices(individuals, weights=probabilities, k=2)\n",
    "    \n",
    "    return [parent_1, parent_2]\n",
    "\n",
    "\n",
    "  \n",
    "def mutate(child, prob=0.1):\n",
    "    \"\"\"\n",
    "    Randomly mutates an individual according to the probability given by prob parameter\n",
    "    \"\"\"\n",
    "    new_child = copy.deepcopy(child)\n",
    "    for i, char in enumerate(new_child):\n",
    "        if random.random() < prob:\n",
    "            new_value = '1' if char == '0' else '0'\n",
    "            new_child = new_child[:i] + new_value + new_child[i+1:]\n",
    "    \n",
    "    return new_child\n",
    "\n",
    "\n",
    "  \n",
    "def reproduce(individual_1, individual_2):\n",
    "    \"\"\"\n",
    "    Takes 2 individuals, and combines their information based on a\n",
    "    randomly chosen crosspoint.\n",
    "    Each reproduction returns 2 new individuals\n",
    "    \"\"\" \n",
    "    # Randomly generate a integer between 1 and the length of the individuals minus one, which will be the crosspoint\n",
    "    crosspoint = random.randint(1, len(individual_1)-1)\n",
    "    child_1 = individual_1[:crosspoint] + individual_2[crosspoint:]\n",
    "    child_2 = individual_2[:crosspoint] + individual_1[crosspoint:]\n",
    "    child_1, child_2 = mutate(child_1), mutate(child_2)\n",
    " \n",
    "    return [child_1, child_2]\n",
    "\n",
    "\n",
    "  \n",
    "def generation_ahead(population, verbose=False):\n",
    "    \"\"\"\n",
    "    Reproduces all the steps for choosing parents and making \n",
    "    childs, which means creating a new generation to iterate with\n",
    "    \"\"\"\n",
    "    new_population = list()\n",
    "    \n",
    "    for _ in range(int(len(population)//2)):      \n",
    "        # According to the weights calculated before, choose a set of parents to reproduce\n",
    "        parents = choose_parents(population, counter=_)\n",
    "        if verbose: print(f'Parents chosen: {parents}')\n",
    "          \n",
    "        # Reproduce the pair of individuals chose above to generate two new individuals\n",
    "        childs = reproduce(parents[0], parents[1])\n",
    "        if verbose: print(f'Generated children: {childs}\\n')\n",
    "        new_population += childs\n",
    "        \n",
    "    return new_population\n",
    "\n",
    "\n",
    "\n",
    "def main_loop(ind_num, dataframe, max_iter=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Performs all the steps of the Genetic Algorithm\n",
    "    1. Generate random population\n",
    "    2. Fill population with the weights of each individual\n",
    "    3. Check if the goal state is reached\n",
    "    4. Reproduce the population, and create a new generation\n",
    "    5. Repeat process until termination condition is met\n",
    "    \"\"\"\n",
    "    # Generate individuals (returns a list of strings, where each str represents an individual)\n",
    "    individuals = generate_random_individuals(ind_num, 65, 10, verbose)\n",
    "    \n",
    "    # Returns a list of tuples, where each tuple represents an individual and its weight\n",
    "    population = fill_population(individuals, dataframe, verbose)\n",
    "    \n",
    "    # Check if a goal state is reached\n",
    "    # When goal state is reached, fill_population() function returns a str, otherwise continue\n",
    "    if isinstance(population, str):\n",
    "        return population\n",
    "        \n",
    "    # Reproduce current generation to generate a better new one\n",
    "    new_generation = generation_ahead(population, verbose)\n",
    "    \n",
    "    # After the new generation is generated, the loop goes on until a solution is found or until the maximum number of\n",
    "    # iterations are reached\n",
    "    iteration_count = 0\n",
    "    while iteration_count < max_iter:\n",
    "        if verbose: print(f'\\n\\n\\nITERATION NUMBER {iteration_count+1} (Iteration max = {max_iter+1})\\n\\n\\n')\n",
    "        population = fill_population(new_generation, dataframe, verbose)\n",
    "        \n",
    "        # Check if a goal state is reached\n",
    "        if isinstance(population, str):\n",
    "            break\n",
    "        \n",
    "        new_generation = generation_ahead(population, verbose)   \n",
    "        iteration_count += 1\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54499cf",
   "metadata": {},
   "source": [
    "## Create and train the model with the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51855ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=dataframe.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframes for both training and testing\n",
    "X_train, X_test, y_train, y_test = generate_dataframes_for_training(dataframe)\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train, y_train, epochs=128, verbose=1)\n",
    "print('Time elapsed for training the model with the full dataset: ', time.time() - start, ' seconds')Get metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b861ff",
   "metadata": {},
   "source": [
    "### Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7546b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: ', recall_fun(y_test, pred.round()))\n",
    "print('Precision: ', precision_fun(y_test, pred.round()))\n",
    "print('F1 Score: ', f1_fun(y_test, pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46258f06",
   "metadata": {},
   "source": [
    "## Create and train the model with the optimized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ed934",
   "metadata": {},
   "source": [
    "### First, the relevant features must be selected by applying the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c995d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "final_population = main_loop(100, exp_df, verbose=True)\n",
    "print('Time elapsed for executing the recursive GA: ', time.time() - start, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68983743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the individual with highest weight\n",
    "max = -99\n",
    "for i in range(len(final_population)):\n",
    "    if final_population[i][1] > max:\n",
    "        max = final_population[i][1]\n",
    "        max_ind = final_population[i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90398ac3",
   "metadata": {},
   "source": [
    "### Finally, leave only the relevant features and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a509a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_dataframe = dataframe.loc[:, [True if char == '1' else False for char in max_ind+'0']]\n",
    "optimized_dataframe['Churn'] = dataframe['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55207026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=optimized_dataframe.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d768065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframes for both training and testing\n",
    "X_train, X_test, y_train, y_test = generate_dataframes_for_training(dataframe)\n",
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb11142",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(X_train, y_train, epochs=128, verbose=1)\n",
    "print('Time elapsed for training the model with the full dataset: ', time.time() - start, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4532e",
   "metadata": {},
   "source": [
    "### Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8812fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall: ', recall_fun(y_test, pred.round()))\n",
    "print('Precision: ', precision_fun(y_test, pred.round()))\n",
    "print('F1 Score: ', f1_fun(y_test, pred.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
